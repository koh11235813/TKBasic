{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMTC9Xp7RW0t"
      },
      "source": [
        "# 機械学習の実装 3 （ハイパーパラメータ調整）\n",
        "\n",
        "前章までにも何度か紹介していたハイパーパラメータの調整方法について学びます。  \n",
        "本章では、モデルの予測精度を向上させるための重要な概念になるハイパーパラメータについて基礎的な概要から、具体的な調整方法と調整後の検証方法までの一連手順を解説します。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvVWmZRaroT"
      },
      "source": [
        "## 本章の構成\n",
        "\n",
        "- ハイパーパラメータの概要と交差検証\n",
        "- ハイパーパラメータの調整方法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUlxkWSQRW0v"
      },
      "source": [
        "## ハイパーパラメータの概要と交差検証\n",
        "\n",
        "\n",
        "### ハイパーパラメータとは\n",
        "パラメータはモデルの学習実行後に獲得される値を指していました。  \n",
        "\n",
        "ハイパーパラメータは各アルゴリズムに付随して、アルゴリズムの挙動を制御するための値です。  \n",
        "**学習の実行前**に設定値を調整することでモデルの性能向上や、過学習を抑制することができます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sfdf9ParoU"
      },
      "source": [
        "### ホールドアウト法\n",
        "前章までは与えられたデータセットを学習用データセット・テスト用データセットを 2 分割しましたが、実際の開発時にはモデルの性能評価をより適切にするためにデータを 3 分割してモデルを評価する必要があります。  \n",
        "\n",
        "| データ名称 | 使用目的                                         |\n",
        "| ------ | -------------------------------------------- |\n",
        "| 学習用データセット (train) | モデルを学習させるためのデータセット                       |\n",
        "| 検証用データセット (validation) | ハイパーパラメータの調整が適切なのか検証するためのデータセット |\n",
        "| テスト用データセット (test)| 学習済みモデルの性能を評価するためのデータセット     |\n",
        "\n",
        "学習用データセットと検証用データセットは学習段階で用いられ、テスト用データセットはモデルの予測精度の確認のためにのみ使用するということを抑えておきましょう。  \n",
        "\n",
        "しかし、十分なデータ量が用意できない場合には 3 分割すると偏りが生じて適切な学習・検証が行われない可能性があります。  \n",
        "そのようなデータの偏りを回避する方法として**K-分割交差検証（ K-fold cross-validation ）**があります。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuiDYfIharoV"
      },
      "source": [
        "### K-分割交差検証（ K-fold cross-validation ）\n",
        "\n",
        "K-分割交差検証は 3 つのステップから構成されており、視覚的に確認すると分かり易いため、図で解説していきます。   \n",
        "前提として、K-分割交差検証は学習用データセットと検証用データセットの分割に用いることが多いです。そのため、下記の図ではテスト用データセットは既に別途分割している事とします。\n",
        "\n",
        "まず第 1 ステップとして、データセットを k 個に分割します。  \n",
        "下記の例では分割数 k を 5 にしています。\n",
        "\n",
        "\n",
        "![Cross Validation1](http://drive.google.com/uc?export=view&id=1fh67YiQ5cVLnR_dKz2mMokHCaBd-Yz0w)\n",
        "\n",
        "第 2 ステップとして、分割したデータの 1 つを検証用データセットとし、残りを学習用データセットとして学習を実行します。  \n",
        "\n",
        "ここで重要なポイントとして 1 回で学習を終わらせず、計 k 回の学習を行います。  \n",
        "その際、既に検証用データセットに使ったデータを次は学習用データセットとして使用し、新たに検証用データセットを選択します。    \n",
        "\n",
        "![Cross Validation2](http://drive.google.com/uc?export=view&id=1HIBW4SkXnlebY47Y2geCS4kVXcKN0kyV)\n",
        "\n",
        "\n",
        "第 3 ステップとして、各検証の結果を平均して最終的な検証結果とします。  \n",
        "このようにすれば、データに偏りなくハイパーパラメータのチューニングを行うことができます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Ni--kBaroW"
      },
      "source": [
        "## ハイパーパラメータの調整方法\n",
        "\n",
        "ハイパーパラメータの概要と検証方法が分かったので、続いて具体的な調整方法を見て行きましょう。  \n",
        "調整方法については代表的な 4 つの方法を紹介します。  \n",
        "\n",
        "アルゴリズムには決定木を使用し、それぞれの方法でハイパーパラメータ調整を行っていきます。\n",
        "\n",
        "- 手動での調整  \n",
        "- **グリッドサーチ （Grid Search）**  \n",
        "- **ランダムサーチ （Random Search）**  \n",
        "- **ベイズ最適化 （Bayesian Optimization）**  \n",
        "\n",
        "### 手動での調整\n",
        "\n",
        "まずは手動でハイパーパラメータの調整を行い、予測精度にどのような変化があるのかを確認しましょう。    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtAUO_qvRW0v"
      },
      "source": [
        "# 必要なモジュールをインポート\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNmdxMBbarob"
      },
      "source": [
        "今回は scikit-learn に準備されている、乳がんに関するデータセットを使用します。  \n",
        "陰性か陽性の 2 つの値が目標値にある、2 値分類の問題設定になります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdgsAoVYRW0y"
      },
      "source": [
        "# 乳がんに関するデータセットの読み込み\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "dataset = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv-snup8RW00"
      },
      "source": [
        "t = dataset.target\n",
        "x = dataset.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hvQLv4ORW02"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_uXsUpkRW06"
      },
      "source": [
        "t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K4evH-nRW08"
      },
      "source": [
        "まずは先ほど紹介した通りデータを学習用データセット・検証用データセット・テスト用データセットの 3 つに分割します。    \n",
        "以下の手順で分割すると理解しておきましょう。  \n",
        "\n",
        "- 与えれたデータを「テスト用データセット：その他＝ 20 ： 80 」に分割\n",
        "- 「その他」のデータを「検証用データセット：学習用データセット＝ 30 ： 70 」に分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6scoBfCRW09"
      },
      "source": [
        "# テスト用データセット：その他＝ 20% ： 80%\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_val, x_test, t_train_val, t_test = train_test_split(x, t, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb76fg_kRW0_"
      },
      "source": [
        "# 検証用データセット：学習用データセット＝ 30 ： 70\n",
        "x_train, x_val, t_train, t_val = train_test_split(x_train_val, t_train_val, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4iaf0g2RW1A"
      },
      "source": [
        "分割処理の後に念のためサイズを確認するよう癖づけておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nh5Ol4zRW1C"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGvYoVhURW1E"
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ocFGxKgRW1G"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdTsracbRW1J"
      },
      "source": [
        "データセットの準備が整ったので決定木の実装を行いましょう。  \n",
        "ハイパーパラメータの調整は行わずに、デフォルトで設定されている値を使用して、学習を行い、予測精度を確認します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwOa7d0RW1J"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(random_state=0) # 再現性の確保"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beKDZVzURW1L"
      },
      "source": [
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAvlHn6WRW1O"
      },
      "source": [
        "print('train : ', model.score(x_train, t_train))\n",
        "print('validation : ', model.score(x_val, t_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwQogMxuRW1R"
      },
      "source": [
        "訓練用データセットに対して 100%、検証用データセットに対して 92.7% の予測精度が確認できました。  \n",
        "学習用データセットに対しての予測精度が高く、検証用データセットに対しては予測精度が低いという、過学習の傾向があることがわかります。  \n",
        "\n",
        "過学習を抑制するハイパーパラメータを調整を行い、再度モデルの学習を行いましょう。  \n",
        "`DecisionTreeClassifier()` メソッドの引数にハイパーパラメータの設定を記述します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MxMQrQqRW1S"
      },
      "source": [
        "# ハイパーパラメータを設定して、モデルの定義\n",
        "model = DecisionTreeClassifier(max_depth=10, min_samples_split=30, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gye8lxKhRW1V"
      },
      "source": [
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sju6kSMIRW1X"
      },
      "source": [
        "print('train : ', model.score(x_train, t_train))\n",
        "print('validation : ', model.score(x_val, t_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDCO8fH_arpV"
      },
      "source": [
        "ハイパーパラメータの調整によって先ほどとは異なった結果が得られ、検証用データセットに対して 92.7% → 95.6% といった予測精度の向上が確認できました。  \n",
        "テスト用データセットに対しても予測精度を検証してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mkcSJj_arpV"
      },
      "source": [
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SRWfFaVRW1a"
      },
      "source": [
        "### グリッドサーチ\n",
        "\n",
        "先程の例では手動で適当にハイパーパラメータの値を決めました。  \n",
        "しかし、適当に入れた値が常に最適なハイパーパラメータである可能性は低いと言えるでしょう。最適なハイパーパラメータを獲得するにはある程度の探索（試行錯誤）を行う必要があります。    \n",
        "\n",
        "効率的に最適なハイパーパラメータを探索する方法はいくつかあります。  \n",
        "その内の 1 つがグリッドサーチになります。    \n",
        "\n",
        "グリッドサーチはまず、ハイパーパラメータを探索する範囲を決めます。例えば下記の図のように決定木の `max_depth` と `max_leaf_nodes` の値を調整したい場合、5、10、15、20、25 のように範囲をそれぞれ決めます。（範囲の指定に特に決まりはありません。）  \n",
        "この場合のハイパーパラメータの組み合わせは 5 x 5 = 25 個になります。この 25 個のハイパーパラメータの組み合わせ全てを使用して、学習・検証を行います。そして、その結果から予測精度が最も高いハイパーパラメータを採用します。  \n",
        " \n",
        "しかし、グリッドサーチにはデメリットも存在します。  \n",
        "実装方法を確認する前に整理しておきましょう。\n",
        "\n",
        "- メリット：指定した範囲を全て網羅するため、漏れがなくハイパーパラメータの探索を行うことができる\n",
        "- デメリット：場合によっては、数十～数百パターンの組合せを計算するため学習に時間を要する\n",
        "\n",
        "![グリッドサーチ](http://drive.google.com/uc?export=view&id=1Yj_ruzw3WoFC7fgGusTGz7MzoiZQVejC)\n",
        "\n",
        "\n",
        "グリッドサーチの概要が理解できたところで、実装を行います。  \n",
        "グリッドサーチの実装は scikit-learn の中で準備されている `GridSearchCV` クラスを用いて実装を行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voxRYw2aRW1a"
      },
      "source": [
        "# GridSearchCV クラスのインポート\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qakrnuaRRW1c"
      },
      "source": [
        "`GridSearchCV` クラスの使用には下記の 3 つを準備する必要があります。  \n",
        "\n",
        "- `estimator` ：学習に使用するモデル  \n",
        "- `param_grid` ：ハイパーパラメータを探索する範囲  \n",
        "- `cv` ：K-分割交差検証の k の値  \n",
        "\n",
        "まずは `estimator` を定義します。 `estimator` はこれまでモデルの定義で定義していたモデルを指します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWH9yZWvRW1d"
      },
      "source": [
        "# 学習に使用するアルゴリズムの定義\n",
        "estimator = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QzrBNZkarpe"
      },
      "source": [
        "ハイパーパラメータの探索する範囲を指定します。  \n",
        "範囲の指定は、辞書型で調整するハイパーパラメータの名前を Key に、 リスト型の探索する範囲を Value に格納します。  \n",
        "調整するハイパーパラメータの名前を間違うとエラーになるため、確認して名前を記述するようにしましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxmukYneRW1f"
      },
      "source": [
        "# ハイパーパラメータを探索する範囲の定義\n",
        "param_grid = [{\n",
        "    'max_depth':[3, 20, 50] , \n",
        "    'min_samples_split':[3, 20, 30]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHLCskjY-j5d"
      },
      "source": [
        "# 分割数 k の値の定義\n",
        "cv = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQTSvG3ARW1i"
      },
      "source": [
        "`Grid SearchCV` では K-分割交差検証が行われます。  \n",
        "そのため、学習用データセットと検証用データセットに分割する前のデータセットである `x_train_val` と `t_train_val` を使用します。  \n",
        "`return_train_score=False` を設定することで学習に対する予測精度の検証が行われません。もし、検証を行う際には `True` に変更します。`False` にするメリットは計算コストを抑えることにあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAy1EYKaRW1i"
      },
      "source": [
        "# GridSearchCV クラスを用いたモデルの定義\n",
        "tuned_model = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=cv, return_train_score=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB0_Qpxaarpq"
      },
      "source": [
        "`GridSearchCV` クラスでも、これまでと同様に `fit()` メソッドでモデルの学習を行うことができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Oaq901RW1k"
      },
      "source": [
        "# モデルの学習＆検証\n",
        "tuned_model.fit(x_train_val, t_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4qhSMUWarpu"
      },
      "source": [
        "学習結果は `cv_results_` で確認することができます。  \n",
        "辞書型で格納されているため、Pandas のデータフレーム型に変換して確認すると見やすく表示することができます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUd8eqZRW1n"
      },
      "source": [
        "# 検証結果の確認\n",
        "pd.DataFrame(tuned_model.cv_results_).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekfbr7W0RW1q"
      },
      "source": [
        "ハイパーパラメータの種類が 2 つで、各 3 個ずつ値を指定したので 3 × 3 = 9 パターンの計算が行われています。  \n",
        "また、k を 5 としたので 5 種類の結果( `split0_test_score` ~ `split4_test_score`  )が出力されています。  \n",
        "\n",
        " それぞれの項目の概要は下記になります。  \n",
        " \n",
        " | 項目名                  | 説明                                                  |\n",
        "| :---------------------- | ----------------------------------------------------- |\n",
        "| mean_fit_time           | 学習時間の平均                                        |\n",
        "| std_fit_time            | 学習時間の標準偏差                                    |\n",
        "| mean_score_time         | 検証時間の平均                                        |\n",
        "| std_score_time          | 検証時間の標準偏差                                    |\n",
        "| param_max_depth         | max_depth の値                                        |\n",
        "| param_min_samples_split | min_samples_split の値                                |\n",
        "| params                  | 調整しているハイパーパラメータの値                    |\n",
        "| split0_test_score       | 交差検証 1 回目の検証用データセットに対しての予測精度 |\n",
        "| split1_test_score       | 交差検証 2 回目の検証用データセットに対しての予測精度 |\n",
        "| split2_test_score       | 交差検証 3 回目の検証用データセットに対しての予測精度 |\n",
        "| split3_test_score       | 交差検証 4 回目の検証用データセットに対しての予測精度 |\n",
        "| split4_test_score       | 交差検証 5 回目の検証用データセットに対しての予測精度 |\n",
        "| mean_test_score         | 検証用データセットに対しての予測精度の平均            |\n",
        "| std_test_score          | 検証用データセットに対しての予測精度の標準偏差        |\n",
        "| rank_test_score         | 検証用データセットに対しての予測精度の順位            |\n",
        " \n",
        "`mean_test_score` の値を確認するとそのモデルの予測精度の確認ができます。基本的にはこの値を確認し、どのハイパーパラメータが効果が強いのかを確認します。   \n",
        " \n",
        " \n",
        "その後、結果を参照して先ほどより狭い範囲でハイパーパラメータを調整します。  \n",
        "これを何度か繰り返すことで徐々に予測精度が高くなるハイパーパラメータへと近づけて行きます。    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH33_PFARW1r"
      },
      "source": [
        "estimator = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXUQgqkSRW1t"
      },
      "source": [
        "param_grid = [\n",
        "    {'max_depth':[5, 10, 15] , 'min_samples_split':[10, 12, 15]}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0t5IkBy_LMs"
      },
      "source": [
        "cv = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CeS0vPyRW1v"
      },
      "source": [
        "# モデルの定義\n",
        "tuned_model = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=cv, return_train_score=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri4xnlujRW1y"
      },
      "source": [
        "# モデルの学習＆検証\n",
        "tuned_model.fit(x_train_val, t_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MmhqH4rRW11"
      },
      "source": [
        "# 学習結果の確認\n",
        "pd.DataFrame(tuned_model.cv_results_).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QbNlaHmRW14"
      },
      "source": [
        "グリッドサーチ 2 回目の結果を確認できました。  \n",
        "このように、最初はある程度大きな幅を持ってグリッドサーチを行い、徐々に範囲を狭めてより予測精度の高いハイパーパラメータを探していきます。  \n",
        "\n",
        "最後にテストデータを用いて、グリッドサーチで学習させたモデルの予測精度を確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV7h8EcORW15"
      },
      "source": [
        "# 最も予測精度の高かったハイパーパラメータの確認\n",
        "tuned_model.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJA63vcCarqH"
      },
      "source": [
        "`best_estimator_` で最も検証用データセットに対しての予測精度が最も高かったハイパーパラメータで学習したモデルを取得することができます。  \n",
        "取得したモデルを新たに `model` という変数に格納します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue33v6RZRW17"
      },
      "source": [
        "# 最も予測精度の高かったモデルの引き継ぎ\n",
        "model = tuned_model.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNPZPA14RW19"
      },
      "source": [
        "# モデルの検証\n",
        "print(model.score(x_train_val, t_train_val))\n",
        "print(model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5nlgPBbarqP"
      },
      "source": [
        "先程手動でハイパーパラメータの調整を行ったモデルのテスト用データセットに対する予測精度より精度が向上していることが確認できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhkud_rmBBBW"
      },
      "source": [
        "### ランダムサーチ\n",
        "\n",
        "グリッドサーチの 1 つの欠点として、指定した全てのハイパーパラメータを探索する点にあります。  \n",
        "全てを探索するということはそれだけ計算コストが増えることを意味します。  \n",
        "\n",
        "そこで、ランダムサーチは指定した範囲のハイパーパラメータをランダムに抽出し、学習・検証を行います。  \n",
        "この方法により、広い範囲を探索することがより効率的に可能になります。  \n",
        "\n",
        "しかし、もちろん全てのハイパーパラメータを探索するわけではないため、そのハイパーパラメータが最適化は判断が難しい点がランダムサーチの欠点と言えるでしょう。  \n",
        "\n",
        "文献の中では、経験的にグリッドサーチと比較して、ランダムサーチの方が効率的にハイパーパラメータを探索することができるケースもあると説明しているものもあります。ランダムサーチの詳細は[こちら](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)を参照してください。\n",
        "\n",
        "実装方法を確認しましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhI6XbKjCi0m"
      },
      "source": [
        "# RandomizedSearchCV クラスのインポート\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc_qlbBbCv7M"
      },
      "source": [
        "# 学習に使用するアルゴリズム\n",
        "estimator = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrijsRgQarqZ"
      },
      "source": [
        "ハイパーパラメータを探索する範囲の指定します。   \n",
        "指定方法はグリッドサーチと同様になります。今回はランダムサーチの挙動を確認するために、範囲を少し広げて指定します。  \n",
        "範囲の指定に `range(開始値, 終了値, ステップ)` を使用します。例えば `range(1, 10, 2)` の場合、 1 から 10 までの値を 2 刻みで獲得できます。その値を `list()` でリスト化しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0PAzCERarqa"
      },
      "source": [
        "list(range(1, 10, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjb_UQerCv7O"
      },
      "source": [
        "# ハイパーパラメータを探索する範囲の指定\n",
        "param_distributions ={'max_depth':list(range(5, 100, 2)) , 'min_samples_split':list(range(2, 50, 1))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T3ZrbG3arqg"
      },
      "source": [
        "ランダムサーチはグリッドサーチ異なり、指定した範囲のハイパーパラメータをランダムに抽出し学習を行うため、何回学習を試行するかの回数を指定する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmPhS5iDgOf"
      },
      "source": [
        "# 試行回数の指定\n",
        "n_iter = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH4G4TW1arqm"
      },
      "source": [
        "`RandomizedSearchCV` クラスでも k-分割交差検証が行われるため、 k の値を指定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AeNO1DzCv7P"
      },
      "source": [
        "cv = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94l0S7Y9arqr"
      },
      "source": [
        "ランダムにハイパーパラメータが抽出されるため、再現性の確保のために乱数のシードの固定を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR_XmRGyDkB2"
      },
      "source": [
        "# 乱数のシードの固定\n",
        "random_state = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dny9rDCarqv"
      },
      "source": [
        "定義した値を用いてモデルの定義を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNC1Lq1BCv7Q"
      },
      "source": [
        "# モデルの定義\n",
        "tuned_model = RandomizedSearchCV(estimator=estimator, param_distributions=param_distributions, n_iter=n_iter, cv=cv, random_state=random_state, return_train_score=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HSiQf_SCv7T"
      },
      "source": [
        "# モデルの学習＆検証\n",
        "tuned_model.fit(x_train_val, t_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eJ-DyIDarq4"
      },
      "source": [
        "今回試行回数を 100 回に設定しているため、学習結果を検証用データセットに対しての順位を表す `rank_test_score` の値を基準に昇順に並び替えて表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZacKLdgdCv7V"
      },
      "source": [
        "# 学習結果の確認（スコアの高い順に表示）\n",
        "pd.DataFrame(tuned_model.cv_results_).sort_values('rank_test_score').T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evkTEJPtarq7"
      },
      "source": [
        "`params` の値を確認しましょう。  \n",
        "それぞれのハイパーパラメータがランダムに組み合わせられていることが確認できます。  \n",
        "\n",
        "最も検証用データセットに対しての予測精度が高かったモデルを取得し、テスト用データセットに対しての予測精度を確認しましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWIC0GmyFSPh"
      },
      "source": [
        "# 最も予測精度の高かったハイパーパラメータの確認\n",
        "tuned_model.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHF2QP7FSPl"
      },
      "source": [
        "# 最も予測精度の高かったモデルの引き継ぎ\n",
        "model = tuned_model.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOd-gHwPFSPm"
      },
      "source": [
        "# モデルの検証\n",
        "print(model.score(x_train_val, t_train_val))\n",
        "print(model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EleHuMXJCjH4"
      },
      "source": [
        "ランダムサーチは前述の通り、指定したハイパーパラメータを網羅していないので完全とは言えないですが、どこに予測精度が高くなるハイパーパラメータがあるのかあたりをつける目的では非常に有用です。  \n",
        "\n",
        "ランダムサーチで大体のいい予測精度に繋がるハイパーパラメータのあたりをつけ、グリッドサーチを用いてより詳細な探索を行うという方法もよく用いられる方法の 1 つになります。それぞれのハイパーパラメータの調整方法には長所と短所があることを理解しておきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq56h3fERW1_"
      },
      "source": [
        "### ベイズ最適化\n",
        "最後にベイズ最適化についてお伝えします。  \n",
        "\n",
        "ベイズ最適化では、事前分布と事後分布と呼ばれる確率統計の理論を使用してハイパーパラメータの探索を行います。  \n",
        "その際、**探索**と**活用**と呼ばれる試行錯誤を繰り返します。イメージとしては人間が行う試行錯誤に近いものがあります。  \n",
        "ハイパーパラメータ探索を手動で行う際、まず初めに適当な値を入れるでしょう。そして、もう一度適当な値を入れて 1 度目の予測精度と比較し、次の探索する場所を決めていきます。このように未知の領域に対して適当に値を当てはめることを探索、探索により得た情報を元にハイパーパラメータを設定することを活用と呼びます。  \n",
        "\n",
        "探索と活用をまとめると下記のように表現することができます。  \n",
        "\n",
        "- 探索：まだ試していない値の範囲でハイパーパラメータを更新して、予測精度がどう変化するか情報を得る。  \n",
        "- 活用：探索で得られた情報をもとに、予測精度が高まる可能性が高い範囲にハイパーパラメータを更新する。  \n",
        "\n",
        "この手法は数学的背景の理解が難しいため、厳密な説明は省略します。\n",
        "詳細は[こちら](https://en.wikipedia.org/wiki/Bayesian_optimization)を参照してください。  \n",
        "\n",
        "ランダムサーチでは、ランダムにハイパーパラメータの値を抽出し学習を行いましたが、ベイズ最適化では探索や活用で得られた情報を元にハイパーパラメータを調整していくため、より効率的に予測精度が高くなるハイパーパラメータを見つけることができると言われています。  \n",
        "\n",
        "ベイズ最適化を実装するためには **Optuna** というフレームワークを使用します。Optuna に関しての詳細はこちらの[公式ページ](https://optuna.org/)を参照してください。  \n",
        "実装時のオプションの詳細などに関してはこちらの[公式ドキュメント](https://optuna.readthedocs.io/en/latest/index.html)を確認してください。  \n",
        "\n",
        "Colab には Optuna はインストールされていないため、下記のコマンドを実行してインストールを行います。その他のパッケージも基本的には下記のように `pip install パッケージ名` でインストールできることも覚えておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvmjvkQfarrI"
      },
      "source": [
        "# optuna のインストール\n",
        "!pip install -q optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqcqzTPA_tiy"
      },
      "source": [
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmAKDJHRMcCd"
      },
      "source": [
        "`optuna` では最初に関数 `objective` を定義して内部に以下の要素を定義します。    \n",
        "- ① ハイパーパラメータごとに探索範囲を指定\n",
        "- ② 学習に使用するアルゴリズムを指定\n",
        "- ③ 学習の実行、検証結果の表示\n",
        "\n",
        "探索範囲の指定にはデフォルトで準備されている `trial` クラスを使用します。      \n",
        "目的に応じて設定方法が異なるので、詳細は[公式ドキュメント](https://optuna.readthedocs.io/en/latest/reference/trial.html#)を参照してください。  \n",
        "\n",
        "③では学習・検証を繰り返してハイパーパラメータの調整を行うのですが、その際に `return` で取得した検証結果を最小化するように調整が進みます。そのため、 `return` で返す値は`1 - accuracy` （ 1 - 予測精度 = 誤分類した割合）とします。  \n",
        "\n",
        "また、③でk-分割交差検証を使用するには `cross_validate` が必要である点も認識しておきましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwhXJ-Sd_59Z"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial, x, t, cv):  \n",
        "  #  ① ハイパーパラメータごとに探索範囲を指定\n",
        "  max_depth = trial.suggest_int('max_depth', 2, 100)\n",
        "  min_samples_split = trial.suggest_int('min_samples_split', 2, 100)\n",
        "  \n",
        "  # ② 学習に使用するアルゴリズムを指定\n",
        "  estimator = DecisionTreeClassifier(\n",
        "      max_depth = max_depth, \n",
        "      min_samples_split = min_samples_split\n",
        "  )\n",
        "  \n",
        "  # ③ 学習の実行、検証結果の表示\n",
        "  print('Current_params : ', trial.params)\n",
        "  accuracy = cross_val_score(estimator, x, t, cv=cv).mean()\n",
        "  return 1 - accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtF8FmqXPDva"
      },
      "source": [
        "準備が整ったら `study.optimize` を定義・実行してハイパーパラメータの調整を行います。  \n",
        "`lambda` を使用して `objective` 関数に追加の引数を渡す点と、 `n_trials` で試行回数を指定する点を抑えておきましょう。    \n",
        "※詳細は[公式ドキュメント](https://optuna.readthedocs.io/en/latest/faq.html)を確認してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRtbDY5n_6Ov"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(0)) # シードの固定\n",
        "\n",
        "cv = 5\n",
        "study.optimize(lambda trial: objective(trial, x_train_val, t_train_val, cv), n_trials=10)\n",
        "print(study.best_trial)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaK5ZiWKRW2U"
      },
      "source": [
        "`print` で出力している値はハイパーパラメータの値になります。  \n",
        "学習が完了するたびに、現在の 1 - 正解率を表す `resulted in value` と現在までの最も良かった 1 - 正解率 を表示しています。  \n",
        "\n",
        "学習が終了したので、最も予測精度の高かったハイパーパラメータを確認するために `study.best_params` を実行します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RK7ehB0RW2V"
      },
      "source": [
        "# 最も予測精度の高かったハイパーパラメータの確認\n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RFwhZr7SQwt"
      },
      "source": [
        "Optuna でのハイパーパラメータ調整は先ほどと異なり、最も予測精度の高かったハイパーパラメータのみが取得でき、学習済みモデルは取得することができないため、再度学習を行う必要があります。  \n",
        "\n",
        "下記のように `**` のようにアスタリスクを 2 つ付け、先程のハイパーパラメータをモデルのインスタンス化を行う際に引数に渡すことで、ハイパーパラメータを設定することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjhKihGZRW2Y"
      },
      "source": [
        "# 最適なハイパーパラメータを設定したモデルの定義\n",
        "model = DecisionTreeClassifier(**study.best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyicdXESarro"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train_val, t_train_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ68QYZxRW2b"
      },
      "source": [
        "# モデルの検証\n",
        "print(model.score(x_train_val, t_train_val))\n",
        "print(model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiOGJB9rarrx"
      },
      "source": [
        "ベイズ最適化を用いてもハイパーパラメータ調整が行うことができました。  \n",
        "それぞれの手法を引き出しとしてもち、それぞれの長所・短所を踏まえた上で手法を選択できるようにしましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQogdUBCarry"
      },
      "source": [
        "## 練習問題 本章のまとめ\n",
        "\n",
        "本章で学んだ内容を復習しましょう。下記の内容を次のセルに記述し、実行結果を確認してください。（必要に応じてセルの追加を行ってください。）  \n",
        "\n",
        "- コードセルを実行し、データセットを読み込み入力変数 `x` と目標値 `t` の取得\n",
        "- 訓練用データセット＆検証用データセット (`x_train_val`, `t_train_val`) とテスト用データセット (`x_test`, `t_test`) に分割（テストデータの割合 : 20% 、random_state : 0 ）\n",
        "- `GridSearchCV` クラスを用いて学習＆検証を行うために必要な値の定義\n",
        "    - 学習に使用するアルゴリズム : 決定木\n",
        "    - 探索するハイパーパラメータの範囲\n",
        "    - k-分割交差検証の k の値 ： 5\n",
        "- 上記で定義した値を用い、`GridSearchCV` クラスをインスタンス化\n",
        "- モデルの学習、検証\n",
        "- 検証結果の確認\n",
        "\n",
        "*ヒント*  \n",
        "探索するハイパーパラメータとその範囲は自分で設定してみましょう。  \n",
        "また、一度学習と検証を実行し、その検証結果から更にハイパーパラメータの範囲を調整し、もう一度探索する範囲を限定して、学習と検証を実行してみましょう。    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NJjWbNXarrz"
      },
      "source": [
        "# データセットの読み込み\n",
        "from sklearn.datasets import load_iris\n",
        "dataset = load_iris()\n",
        "x = dataset.data\n",
        "t = dataset.target\n",
        "columns = dataset.feature_names\n",
        "df = pd.DataFrame(x, columns=columns)\n",
        "df['Target'] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmrj1uawarr1"
      },
      "source": [
        "# データセットの確認\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX9KUQVbarr9"
      },
      "source": [
        "# 訓練用データセット＆検証用データセットとテスト用データセットに分割（テストデータの割合 : 20% 、random_state : 0）\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_val, x_test, t_train_val, t_test = train_test_split(x, t, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TftBRWFWarr_"
      },
      "source": [
        "# 学習に使用するアルゴリズムの定義\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "estimator = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy28VucZarsB"
      },
      "source": [
        "# ハイパーパラメータを探索する範囲の定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUAEBfEQarsC"
      },
      "source": [
        "# k-分割交差検証の k の値の定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgPkng_aarsE"
      },
      "source": [
        "# GridSearchCV クラスを用いたモデルの定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4LcibF8arsG"
      },
      "source": [
        "# モデルの学習＆検証\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBL1rbgsarsH"
      },
      "source": [
        "# 検証結果の確認\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UXN2gsyarsL"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1g2xjXbw5qYeqdJqcOf3uASvzBQxhlE8u\" width=30%>"
      ]
    }
  ]
}