{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TKBasic015_MachineLearning4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e2liKeSRW3y"
      },
      "source": [
        "# 教師なし学習\n",
        "前章までは入力値と目標値をセットで持つ問題設定に対して用いる機械学習の種類である**教師あり学習**を扱いました。    \n",
        "しかし、すべてのデータが目標値を持つわけではありません。  \n",
        "\n",
        "そこで本章では、目標値を持たない問題設定に対して用いる**教師なし学習**を扱います。  \n",
        "教師なし学習には２つの代表的な手法があり、どちらもデータの背後に存在する本質的な構造を抽出する際に用います。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykOloJ48c-aJ"
      },
      "source": [
        "## 本章の構成\n",
        "\n",
        "- 主成分分析 (Principal Component Analysis)\n",
        "- k 平均法 (k-means)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y12FM-UPRW31"
      },
      "source": [
        "## 主成分分析\n",
        "\n",
        "**主成分分析 (Principal Component Analysis)** は**次元削減 (Dimensionality reduction)** の手法になります。  \n",
        "次元削減とは、例えば 4 次元のデータ（列数が 4 つのデータ）があった場合、2 次元などの低次元に落とし込むことを指します。  \n",
        "また、一般的に次元削減は単にデータを削除するのではなく、可能な限り元のデータの情報を保持したまま、低次元のデータに変形を行います。  \n",
        "\n",
        "その次元削減の 1 つの手法として、主成分分析があります。主成分分析は PCA と略されて呼ばれる場合があることも覚えておきましょう。  \n",
        "主成分分析の詳細に関しては[こちら](https://ja.wikipedia.org/wiki/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90)を確認してください。  \n",
        "\n",
        "実際に主成分分析を用いて次元削減を行い、内容を確認しましょう。  \n",
        "データセットは scikit-learn にデフォルトで用意されているアヤメ (Iris) のデータセットを使用します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXUnyAq8c-aL"
      },
      "source": [
        "# モジュールの読み込み\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssHtEeyXRW3z"
      },
      "source": [
        "# データの読み込み\n",
        "from sklearn.datasets import load_iris\n",
        "dataset = load_iris()\n",
        "x = dataset.data\n",
        "t = dataset.target\n",
        "feature_names = dataset.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWELFLKsRW30"
      },
      "source": [
        "# データの確認\n",
        "pd.DataFrame(x, columns=feature_names).head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtC0zzNQc-aS"
      },
      "source": [
        "元のデータは 4 次元あることが確認できます。このデータを主成分分析を用いて、2 次元に落とし込みましょう。  \n",
        "主成分分析の実装もこれまでの実装方法と同じになります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0lbDDoRW32"
      },
      "source": [
        "#  モデルの定義\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIXnkHFlRW33"
      },
      "source": [
        "`n_components` で指定しているのは、次元削減後の次元数です。  \n",
        "今回は 4 次元から 2 次元に次元削減します。理由としては、2 次元であればデータを可視化することが可能というメリットがある点にあります。  \n",
        "\n",
        "モデルの学習では主成分分析を適用するために必要な**共分散　(Covariance)** などの値を算出します。  \n",
        "共分散の詳細は[こちら](https://ja.wikipedia.org/wiki/%E5%85%B1%E5%88%86%E6%95%A3)を確認してください。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3eJK_i-RW34"
      },
      "source": [
        "# モデルの学習\n",
        "pca.fit(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi320Gbqc-aY"
      },
      "source": [
        "# 共分散の確認\n",
        "pca.get_covariance()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwbM1rRNc-aa"
      },
      "source": [
        "算出された共分散を用いて、主成分分析を行います。実行には `transform` メソッド を使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myRSEGvMRW36"
      },
      "source": [
        "# 主成分分析の適用\n",
        "x_transformed = pca.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxAb3S2CRW37"
      },
      "source": [
        "# 主成分分析適用後のデータの確認\n",
        "pd.DataFrame(x_transformed, columns=['第一主成分', '第二主成分']).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp3Q1BU3RW4C"
      },
      "source": [
        "データが 2 次元に落とし込まれていることが確認できました。  \n",
        "\n",
        "1 列目のデータを**第一主成分**と呼び、2 列目を**第二主成分**と呼びます。  \n",
        "それぞれの列は次元削減前の情報を保持しているといえます。それぞれの列が保持する元のデータの情報の割合を**寄与率 (Proportion of the variance)** と呼びます。  \n",
        "寄与率は `fit()` メソッド後の `explained_variance_ratio_` 属性からそれぞれの寄与率を確認することができます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNFKIm8kRW4G"
      },
      "source": [
        "print('第一主成分の寄与率：{}'.format(pca.explained_variance_ratio_[0]))\n",
        "print('第二主成分の寄与率：{}'.format(pca.explained_variance_ratio_[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6MEjKNfRW4I"
      },
      "source": [
        "第一主成分は `92%` 、第二主成分は `5%` ほどの寄与率であることが確認できます。  \n",
        "すなわち `97%` 程度の割合で元のデータの情報を保持したまま次元削減できていることが確認できます。  \n",
        "\n",
        "このように、主成分分析は 100% 情報を保持したまま次元削減を行うのではなく、いくらかの情報は保持できていないことがわかります。  \n",
        "主成分分析を適用した後にはこの寄与率を確認し、元のデータをどの程度再現できているのかを確認することが重要です。  \n",
        "\n",
        "次元削減後のデータを可視化しましょう。  \n",
        "今回はアヤメの花の種類が 3 種類のデータセットを使用しています。可視化を行う際にそれぞれのクラスに色をつけて表示し、次元削減後のデータを確認します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x39j2rWbRW38"
      },
      "source": [
        "# 0, 1, 2 の 3 つのクラスがあることを確認\n",
        "np.unique(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nARh_7kdjyDN"
      },
      "source": [
        "# 散布図で可視化\n",
        "plt.scatter(x_transformed[:,0], x_transformed[:,1], c=t, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG-s37IqRW3_"
      },
      "source": [
        "元のデータセットでは 4 次元のため可視化を行うことができませんでしたが、次元削減を行うことにより、データセットを可視化することができました。  \n",
        "このように可視化することにより、データセットについて直感的に理解できるということは重要です。  \n",
        "\n",
        "例えば今回の可視化結果から、このデータセットで分類を行った場合、ラベル 1（緑）　と ラベル 2（黄）は分類することが少し困難であることが想定することができます。  また、ラベル 0 に関しては機械学習を用いることなく、分類を行うことも可能そうであることがわかります。  \n",
        "\n",
        "次元削減を行うことにより、可視化困難であったデータを可視化することができるということは、大きなメリットがあることが確認できます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSJoDdRSRW4I"
      },
      "source": [
        "## k 平均法\n",
        "\n",
        "**k 平均法 (k-means)** はクラスタリングと呼ばれる手法に当たり、データを複数のクラスター（グループ）に分けて大まかな特徴を捉える際に使用します。直感的には[こちら](http://tech.nitoyon.com/ja/blog/2013/11/07/k-means/)のアニメーションが非常に理解しやすいです。  \n",
        "\n",
        "k 平均法がクラスタリングを行うステップは次の通りです。  \n",
        "\n",
        "1. 人間側がクラスター（グループ）の数を決める  \n",
        "2. ランダムに振られた点（重心）から近いものをクラスターとする  \n",
        "3. 紐づいたクラスターとの距離を元に重心を移動させる  \n",
        "4. 重心が動かなくなるまで 3 を繰り返す  \n",
        "\n",
        "今回はコンビニエンスストアの購買データを元にしてクラスタリングの活用方法を理解していきましょう。  \n",
        "使用するデータは [convinience_store.csv](http://drive.google.com/uc?export=view&id=1FUh97sZ7VTHNx62aEzzHQepERbIKjr8J) をダウンロードしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmXaCnN_c-ap"
      },
      "source": [
        "### colab へのデータアップロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6KilYETeGp"
      },
      "source": [
        "# colabへのアップロード\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KArsm6s8RW4M"
      },
      "source": [
        "df = pd.read_csv('convinience_store.csv')\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn8HWbhyc-au"
      },
      "source": [
        "今回取り扱うデータセットはコンビニエンスストアのそれぞれの顧客の 3 ヶ月の購買履歴になります。  \n",
        "列名の No は顧客 ID を表し、それぞれの顧客がどのカテゴリの商品を何円分購入したかを表しています。  \n",
        "この過去の購買データを元に k 平均法を適用し、顧客をいくつかのクラスター（グループ）に分割します。  \n",
        "\n",
        "k 平均法にデータを適用する際に顧客 ID は使用しないため、予め取り除いておきます。  \n",
        "また、scikit-learn を用いて実装を行うため、同時 NumPy の `array` 形式に変換しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDHXzY2fc-au"
      },
      "source": [
        "#  ID列を削除+Numpy形式に変換\n",
        "x = df.iloc[:, 1:].values\n",
        "x[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoCSKCfzRW4P"
      },
      "source": [
        "### k 平均法の実装\n",
        "\n",
        "実装方法はこれまでの手法と同様の手順で実装することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F6Rod3YRW4P"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMBaS1zMc-az"
      },
      "source": [
        "前述の説明にもある通り、k 平均法では予め分割するクラスター数を決めておく必要あります。  \n",
        "クラスター数を決定するハイパーパラメータは `n_clusters` になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyx8Ww_LRW4R"
      },
      "source": [
        "# モデルの定義\n",
        "model = KMeans(n_clusters=3, random_state=0) # クラスターの数を定義"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVrrBXFnRW4S"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuKBbm_7c-a4"
      },
      "source": [
        "モデルの学習が完了しました。モデルの学習ではそれぞれのクラスターの中心座標を算出し、保持します。  \n",
        "今回取り扱ったデータセットの次元数が 6 次元、そしてクラスターの数を 3 と指定していたため、3 行 6 列の値を確認することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKJVDSulc-a4"
      },
      "source": [
        "# クラスターの中心座標の確認\n",
        "model.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUEPDdWyc-a6"
      },
      "source": [
        "# クラスター数 3、入力変数の数 6 であることが確認できる\n",
        "model.cluster_centers_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ5INKg0c-a8"
      },
      "source": [
        "`.predict()` メソッドで入力の値に対してクラスタリングを適用することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEo8wB4DRW4T"
      },
      "source": [
        "# クラスタリングの適用\n",
        "cluster = model.predict(ｘ)\n",
        "cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcBkWBE_c-a-"
      },
      "source": [
        "予測値が 0 ~ 2 となっていて、ハイパーパラメータで設定したクラスター数と同じことが確認できます。  \n",
        "しかし、この結果からではどのようにクラスタリングされているか判断が難しいため、この情報を元のデータフレームに追加します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmWP0VNRW4U"
      },
      "source": [
        "# データフレームの作成\n",
        "df_cluster = df.copy() # データフレームをコピー\n",
        "df_cluster['cluster'] = cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rMbcvEeRW4V"
      },
      "source": [
        "df_cluster.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS7EhtW3RW4W"
      },
      "source": [
        "### クラスタリング結果の考察\n",
        "\n",
        "クラスタリングした結果、顧客を 3 つのクラスター（グループ）に分けることができました。  \n",
        "しかし、クラスターに分けるだけではどのように活用できるかわかりません。  \n",
        "\n",
        "教師なし学習は教師あり学習と異なり明確な答えが存在しないため、その予測結果がどのようなもので、どのように活用するかに関しては人間側が考慮する必要がある部分であることを覚えておきましょう。  \n",
        "\n",
        "今回分割した 3 つの顧客クラスターに対してどのような活用方法があるのかを考察していきます。  \n",
        "今回は一例として、各クラスターの平均購買金額から考察を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Maf5nnbc-bE"
      },
      "source": [
        "# 空のデータフレームを作成します。\n",
        "df_results = pd.DataFrame()\n",
        "df_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fb3ouzLc-bG"
      },
      "source": [
        "クラスターごとに平均値を算出し、その値を先程作成した空のデータフレームに追加していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyCKyn8TRW4X"
      },
      "source": [
        "df_results['cluster0'] = df_cluster[df_cluster['cluster'] == 0].mean().tolist()\n",
        "df_results['cluster1'] = df_cluster[df_cluster['cluster'] == 1].mean().tolist()\n",
        "df_results['cluster2'] = df_cluster[df_cluster['cluster'] == 2].mean().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gSSMGdc-bJ"
      },
      "source": [
        "df_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_TQO0k4c-bK"
      },
      "source": [
        "行が先ほどのデータフレームの列名に当てはまるため、行に列名を当てはめます。  \n",
        "また転置し、列がそれぞれの項目、行がクラスターになるように変更します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH3S1euCc-bN"
      },
      "source": [
        "df_results = df_results.set_index(df_cluster.columns) # Index に列名を追加\n",
        "df_results = df_results.drop(['No', 'cluster']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OXtAAzmRW4X"
      },
      "source": [
        "# 結果の表示\n",
        "df_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0DDh7tKRW4Y"
      },
      "source": [
        "それぞれのクラスターの特徴を考察してみましょう。下記のような考察が得られるのではないでしょうか。  \n",
        "\n",
        "- グループ 0 ：全体的に購入金額が少ないが、スイーツの購入金額は最も大きい  \n",
        "- グループ 1 ：弁当・麺類と飲料の購入金額が最も大きい  \n",
        "- グループ 2 ：飲料やスイーツの購入は少ないが、全般的に他の食品類の購入金額が大きい  \n",
        "\n",
        "このように、目的をもってクラスタリング後のデータを加工・分析することでクラスターの特徴を把握することができます。  \n",
        "この考察を用いて、 例えばランチの時間帯に配信するクーポンをグループごとに分ける事で、個々人の趣味嗜好に応じた効果的なマーケティング施策を行うことが可能です。  \n",
        "\n",
        "教師なし学習ではこのように答えが無く、人間側が予測結果からデータの加工を行い、そこから活用方法の考察を行う必要がある点を覚えておきましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4lm6F3lc-bR"
      },
      "source": [
        "## 練習問題 本章のまとめ\n",
        "\n",
        "本章で学んだ内容を復習しましょう。下記の内容を次のセルに記述し、実行結果を確認してください。（必要に応じてセルの追加を行ってください。）  \n",
        "\n",
        "- 先程取り扱ったコンビニエンスストアのデータセットを再度読み込み、`No` の列を削除、NumPy の形式に変換して、変数 `x` に格納\n",
        "- `x` を用いて、k-平均法を適用（ `n_clusters=5` ）し、獲得したクラスターを変数 `cluster` に格納\n",
        "- `x` に対し、主成分分析を適用（ `n_components=2` ）し、結果を変数 `x_transformed` に格納\n",
        "- `x_transformed` を可視化し、先程取得した、変数 `cluster` に格納されている値を用いて色付けを行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNjKFuONc-bR"
      },
      "source": [
        "# データの読み込み\n",
        "df = pd.read_csv('convinience_store.csv')\n",
        "x = df.drop(['No'], axis=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3rinR8uc-bT"
      },
      "source": [
        "`x` を用いて、k-平均法を適用（ `n_clusters=5` ）し、獲得したクラスターを変数 `cluster` に格納"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXPQzV3Yc-bU"
      },
      "source": [
        "# k-平均法のモデルの定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvkWEb3nc-bW"
      },
      "source": [
        "# モデルの学習\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJMiZ6xLc-bY"
      },
      "source": [
        "# クラスタリングの適用\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyuZeEERc-ba"
      },
      "source": [
        "`x` に対し、主成分分析を適用（ `n_components=2` ）し、結果を変数 `x_transformed` に格納"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzRlluBc-bb"
      },
      "source": [
        "# 主成分分析のモデルの定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHxDMrOfc-bd"
      },
      "source": [
        "# モデルの学習\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CqmYlTbc-bf"
      },
      "source": [
        "# 主成分分析の適用\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX0y8_qNc-bj"
      },
      "source": [
        "`x_transformed` を可視化し、先程取得した、変数 `cluster` に格納されているクラスターを用いて色付けを行い可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_SkvG5ec-bk"
      },
      "source": [
        "# 次元削減後のデータの可視化\n",
        "plt.scatter(x_transformed[:, 0], x_transformed[:, 1], c=cluster)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxuzoAQvc-bn"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1g2xjXbw5qYeqdJqcOf3uASvzBQxhlE8u\" width=30%>"
      ]
    }
  ]
}