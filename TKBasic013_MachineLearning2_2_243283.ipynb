{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TKBasic013_MachineLearning2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ucGWtoyVUme"
      },
      "source": [
        "# 機械学習の実装 2 （教師あり学習：分類）\n",
        "前章では教師あり学習の中でも**回帰**と呼ばれる種類の手法を扱いました。  \n",
        "教師あり学習には他にも**分類**と呼ばれる種類の手法があります。  \n",
        "\n",
        "\n",
        "具体的な実装手順は同じですが、それぞれ使用目的が異なるので覚えておきましょう。  \n",
        "本章では分類の実装手順と、代表的な分類のアルゴリズムを紹介して行きます。  \n",
        "\n",
        "- 回帰：数値を予測する際に用いる（売上、株価、販売数量など）  \n",
        "- 分類：カテゴリを予測する際に用いる（犬/猫、男性/女性など）   \n",
        "\n",
        "また、モデルを実装した後には様々な評価指標を用いて予測性能を確認する必要があります。  \n",
        "本章の後半では具体的なモデルの評価方法を学びつつ、なぜモデルを評価する指標を考慮する必要があるのかという背景も抑えて行きましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvlI685VVUmf"
      },
      "source": [
        "## 本章の構成\n",
        "\n",
        "- 決定木の実装で分類の全体像を理解\n",
        "- 代表的な分類のアルゴリズム\n",
        "- 分類の評価方法\n",
        "- scikit-learn で評価指標を確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REQE3LjQeR9A"
      },
      "source": [
        "## 決定木の実装で分類の全体像を理解\n",
        "\n",
        "前章で実装した回帰と同様に、分類も scikit-learn を使用します。    \n",
        "まずは練習に scikit-learn の中の有名なアヤメ (iris)の花のデータセットを使用して実装方法を抑えましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG7FFwHteR9A"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV0vEMaJVUmj"
      },
      "source": [
        "### データの準備\n",
        "\n",
        "今回使用するデータセットはアヤメの花に関する情報とその種類になります。  \n",
        "入力変数として扱うデータは下記になります。今回は下記の情報をもとにアヤメの花の種類を分類する問題設定になります。\n",
        "\n",
        "| 列名         | 説明         |\n",
        "| ------------ | ------------ |\n",
        "| petal length | 花びらの長さ |\n",
        "| petal width  | 花びらの幅   |\n",
        "| sepal length | がく片の長さ |\n",
        "| sepal width  | がく片の幅   |\n",
        "\n",
        "\n",
        "![アヤメの花の種類](http://drive.google.com/uc?export=view&id=13VlpMGGEDCaPTDnyK88YIgcoklIEpaE6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGPX4fgqeR9B"
      },
      "source": [
        "# データセットの読み込み\n",
        "dataset = load_iris()\n",
        "colms_name = dataset.feature_names\n",
        "x = dataset.data\n",
        "t = dataset.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XN59EfgeR9C"
      },
      "source": [
        "# 読み込んだデータセットをデータフレーム形式に変換\n",
        "df = pd.DataFrame(data=x, columns=colms_name)\n",
        "df['Target'] = t\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGuJI8_3VUmo"
      },
      "source": [
        "データセットの読み込みが完了したら、サンプル数、入力変数の数を確認しておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Es6Iz1eR9D"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G3cyW-IeR9E"
      },
      "source": [
        "t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VeNWZi1VUmt"
      },
      "source": [
        "データセットを学習用データセットとテスト用データセットに分割します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3btgfQsHeR9F"
      },
      "source": [
        "# 学習用データセットとテスト用データセットの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcwWc-D3eR9F"
      },
      "source": [
        "### 分類モデルの学習\n",
        "\n",
        "データの準備が整いました。分類のアルゴリズムの実装を行なっていきましょう。  \n",
        "scikit-learn はモデルの定義、学習、検証の 3 ステップでした。回帰の時と同様の手順で実装することができます。  \n",
        "決定木と呼ばれるアルゴリズムを実装します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38kKtloneR9F"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvic-bgFeR9G"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2rd6GreeR9H"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train, t_train))\n",
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNviouFBeR9I"
      },
      "source": [
        "ここで確認できる値は回帰の時に使用した指標である決定係数ではありません。  \n",
        "分類の評価指標はいくつか種類がありますが、`score()` メソッドで表示される値は**正解率 （Accuracy）** が用いられています。  \n",
        "例えば、100 回分類を行い 90 回予測を正しく行えた場合、正解率は 90%（ 0.9 ） です。そのため最小の値は 0 となり最大値は 1 になります。  \n",
        "\n",
        "もう一つの回帰との違いとして、損失関数が挙げられます。  \n",
        "回帰では平均二乗誤差が損失関数として用いられていましたが、分類では[交差エントロピー](https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E3%82%A8%E3%83%B3%E3%83%88%E3%83%AD%E3%83%94%E3%83%BC)が主に用いられことも覚えておきましょう。  \n",
        "\n",
        "このように分類の問題設定でも、scikit-learn を用いての実装は回帰の場合と大きな違いはなく行うことができます。  \n",
        "推論も同様に `predict()` メソッドで実行することが可能です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3sjFvAVUm7"
      },
      "source": [
        "# 推論\n",
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTrvT_LQVUm-"
      },
      "source": [
        "予測値を確認しましょう。予測値は回帰の時の連続値ではなく、離散値であることが確認できます。  \n",
        "このように分類のモデルはクラスを表す数値が表示されます。  \n",
        "今回は 3 種類のアヤメの花の種類の分類の問題設定のため、0 ~ 2 の 3 つのクラスが推論されていることが確認できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbzAkG-5VUm-"
      },
      "source": [
        "### 決定木の特徴\n",
        "\n",
        "木のような構造を用いて、回帰・分類を行うことが可能なアルゴリズムになります。回帰に使用するものを特に回帰木とも呼びます。  \n",
        "どのように分類を行っているかのイメージを掴むためにまずは下記の画像を確認してください。  \n",
        "\n",
        "![決定木 木構造](http://drive.google.com/uc?export=view&id=1KKCuriuG4MmLqcpzzs9yvSY7wN1_261S)\n",
        "\n",
        "決定木は上記の図のように複数の分岐を繰り返すことによって、分類を行います。  \n",
        "一番上の分岐を見ると、petal length（ cm ） <= 2.35 という条件が確認できます。そして、次のステップではその条件に適合していれば True へ、そうでなければ False へと分岐を繰り返します。このように条件分岐を繰り返すことによって、分類を行います。図内の gini という表記は損失を表しています。  \n",
        "\n",
        "決定木の特徴や代表的なハイパーパラメータを確認しましょう。  \n",
        "\n",
        "| 項目                                    | 説明                                                         |\n",
        "| --------------------------------------- | ------------------------------------------------------------ |\n",
        "| **強み**                                | 比較的複雑な問題設定にも対応可能。スケールの違いの影響を受けにくい。解釈が比較的容易。 |\n",
        "| **弱み**                                | 過学習になる場合が多く、汎用性の低いモデルになる傾向がある。           |\n",
        "| **主なハイパーパラメータ**              |                                                              |\n",
        "| *max_depth（木構造の深さの上限）*       | 過学習を抑えるためのハイパーパラメータ。上限が低いとモデルの表現力は低下し、過学習を抑える。 |\n",
        "| *min_samples_split（木構造の分岐の数）* | Max_depth と類似し、数を増やすと表現力が増すが、過学習に陥る可能性が上がる。 |\n",
        "\n",
        "決定木のアルゴリズムの詳細に関してはこちらの[公式ドキュメント](https://scikit-learn.org/stable/modules/tree.html#classification)を確認してください。\n",
        "\n",
        "\n",
        "### 木構造と Feature importance の確認\n",
        "\n",
        "木構造の書き出しには `graphviz` というパッケージを使用します。  \n",
        "Google Colabratorty にはデフォルトでインストールされていますが、お手元の PC などで使用する際には[こちら](https://graphviz.gitlab.io/download/)からインストールを行ってください。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN5SWSxoGzkS"
      },
      "source": [
        "# 木構造の書き出し\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "dot_data = export_graphviz(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pjmSx_WGzkV"
      },
      "source": [
        "# 木構造の表示\n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcgBX0ueR9L"
      },
      "source": [
        "**Feature Importanceの確認**\n",
        "\n",
        "決定木はそのアルゴリズムの特性から、どの入力変数の影響度が高いかを知ることができます。なぜなら、木構造は分岐を繰り返すことから、分岐の上に行くほど分類に対する影響度が高くなるためです。  \n",
        "\n",
        "それぞれの入力変数の影響度を確認するには`.feature_importance_` 属性を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6y-vc7eR9M"
      },
      "source": [
        "# feature importance\n",
        "feature_importance = model.feature_importances_\n",
        "feature_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tls1UIUFVUnG"
      },
      "source": [
        "ヒストグラムを用いて可視化を行い、イメージを掴みやすくします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAY4PPB_eR9N"
      },
      "source": [
        "y = colms_name\n",
        "width = feature_importance\n",
        "\n",
        "#  横向きの棒グラフで表示\n",
        "plt.barh(y=y, width=width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WTxGt4WVUnL"
      },
      "source": [
        "実行結果から petal length という入力変数の影響度が高いことが確認できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxRwswyaRW2e"
      },
      "source": [
        "## 代表的な分類のアルゴリズム\n",
        "\n",
        "\n",
        "### サポートベクトルマシン\n",
        "\n",
        "カーネル関数と呼ばれる関数を用い（カーネルトリック）、入力変数${x_i}$を特徴空間への非線形写像$\\phi（{x_i}）$し、写像後の特徴空間において線形分類を行うアルゴリズムになります。  \n",
        "\n",
        "サポートベクトルマシン (Support vector machine) のカーネルトリックの数学は少しレベルが高いため、まずは[こちらの動画](https://www.youtube.com/watch?v=3liCbRZPrZA&feature=youtu.be)を確認し、イメージを掴みましょう。\n",
        "  \n",
        "\n",
        "| 項目                   | 説明                                                         |\n",
        "| ---------------------- | :----------------------------------------------------------- |\n",
        "| **強み**                   | 未知のデータへの識別性能が比較的強い。ハイパーパラメータの数が少ない。 |\n",
        "| **弱み**                   | 学習する際に必ずデータの標準化（もしくは正規化）を行う必要がある。 |\n",
        "| **主なハイパーパラメータ** |                                                  |\n",
        "| *C（コストパラメータ）*  | 誤った予測に対するペナルティ。大き過ぎると過学習を起こす。 |\n",
        "| *gamma（ガンマ）*        | モデルの複雑さを決定する。値が大きくなるほどモデルが複雑になり過学習を起こす。 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDxDQaeWRW2f"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.svm import SVC #Support Vector Classifier\n",
        "model = SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NOnY3huRW2l"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMXXhvyRW2m"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train, t_train))\n",
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJmnS1xjRW2o"
      },
      "source": [
        "サポートベクターマシンは一般的にデータに対して標準化を適用する必要があります。  \n",
        "今回のデータセットは全て cm を単位としているため、スケールが統一されているため、標準化の必要はありませんが、scikit-learn を用いての実装方法を確認しておきましょう。  \n",
        "\n",
        "実装方法は基本的にはモデルの学習を行う際と同じ流れになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMzHeoefRW2p"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10MuHU2KRW2r"
      },
      "source": [
        "# モデルの学習\n",
        "scaler.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBERxvChVUnc"
      },
      "source": [
        "モデルの学習ではデータセットの平均と標準偏差を算出し、標準化を適用できる準備を行っています。  \n",
        "標準化を行うには `transform()` メソッドを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_JkK7hiRW2t"
      },
      "source": [
        "# 標準化\n",
        "x_train2 = scaler.transform(x_train)\n",
        "x_test2 = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1okAMpPzVUnf"
      },
      "source": [
        "平均 0 、標準偏差 1 となっており、データに対して、標準化が適用されていることが確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TawxubQ8VUnf"
      },
      "source": [
        "# 平均の確認\n",
        "round(x_train2.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cy5HUJOVUnh"
      },
      "source": [
        "# 標準偏差の確認\n",
        "round(x_train2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFzWoH9EVUnk"
      },
      "source": [
        "標準化したデータを用いて学習を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiMAYlpCRW2u"
      },
      "source": [
        "# モデルの定義\n",
        "model = SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMp-JqOIRW2v"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train2, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3lma34LRW2x"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train2, t_train))\n",
        "print('test : ', model.score(x_test2, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G7lBQlTVUnq"
      },
      "source": [
        "今回はスケールがもともと統一されていたため、少し精度が低下しましたが、サポートベクトルマシンを使用する際には必ず標準化を行うことを覚えておきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwMYtWCJVUnq"
      },
      "source": [
        "### k 近傍法\n",
        "\n",
        "k 近傍法 (k-nearest neighbor) はデータ間の距離を用いて分類を行います。具体的なイメージを掴むためにまず下記の画像を確認してください。  \n",
        "\n",
        "![k 近傍法 概要](http://drive.google.com/uc?export=view&id=1RnC_L_dAgmLut74To3BdT_NmGVC-cmBv)\n",
        "\n",
        "上図の中心のオレンジ色のひし形が未知のデータ（学習に使用していない新たなデータ）を表します。  \n",
        "\n",
        "k 近傍法ではまず、ハイパーパラメータである `k` の値を決定します。  \n",
        "未知のデータから距離が近いものから k 個サンプルを抽出し、そのサンプルの中で数の多いクラスに未知のデータを分類します。  \n",
        "\n",
        "図の中では `k=3`、`k=7` の場合の 2 種類の例を確認しましょう。  \n",
        "`k=3` のケースでは未知のデータから最も近い 3 サンプルはラベル 0 が 2 個、ラベル 1 が 1 個となっています。  \n",
        "このケースでは未知のデータはラベル 0 と分類されます。  \n",
        "\n",
        "続いて `k=7` のケースでは未知のデータから最も近い 7 サンプルはラベル 0 が 3 個、ラベル 1 が 4 個となっています。  \n",
        "このケースでは未知のデータはラベル 4 と分類されます。  \n",
        "\n",
        "k 近傍法はあらゆる機械学習の中で最もシンプルなアルゴリズムと呼ばれています。  \n",
        "特徴を確認しましょう。　　　\n",
        "\n",
        "| 項目                       | 説明                                                         |\n",
        "| -------------------------- | ------------------------------------------------------------ |\n",
        "| **強み**                   | 可読性が高い、学習のスピードが早い                           |\n",
        "| **弱み**                   | ハイパーパラメータの影響を大きく受ける。学習用データセットのサンプル数が増えれば推論に時間を要する |\n",
        "| **主なハイパーパラメータ** |                                                              |\n",
        "| *n_neighbors（ k の数）*     | 分類に考慮するサンプル数を決定する                           |\n",
        "\n",
        "詳細に関しては[こちら](https://ja.wikipedia.org/wiki/K%E8%BF%91%E5%82%8D%E6%B3%95)を確認してください。  \n",
        "\n",
        "k 近傍法は異常検知の問題設定にも用いられる手法の 1 つです。  \n",
        "厳密な使用方法は異なりますが、下記の画像を確認してイメージを掴みましょう。  \n",
        "\n",
        "![k 近傍法 異常検知](http://drive.google.com/uc?export=view&id=1i42iFR2yvjdxX-mRYJ7cudDoErRh7hmM) \n",
        "\n",
        "k 近傍法の 1 つの特徴として、サンプル間の距離を知ることが挙げられます。  \n",
        "図内の 𝜀 はあるサンプルの周囲にある k 個のサンプルの中で最も遠いサンプルとの距離になります。  \n",
        "\n",
        "異常データの周囲にある k 個のサンプルの中で最も遠いサンプルとの距離である 𝜀′ は正常データ群のものよりも大きくなっていることがわかります。  \n",
        "この 𝜀 に閾値を設けることにより異常検知を行います。  \n",
        "\n",
        "scikit-learn を用いてアルゴリズムの実装、データ間の距離を確認する方法を確認します。  \n",
        "例として k の数を設定するハイパーパラメータ `n_neighbors` は 5 で設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FPhaWrbVUnr"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9dC-_qsVUnt"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCY0hZyBVUnw"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train, t_train))\n",
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hr-h3bNVUn0"
      },
      "source": [
        "**学習したデータとの距離の確認**  \n",
        "\n",
        "`kneighbors()` メソッドで新たなデータと学習に使用したデータとの距離を確認することができます。  \n",
        "1 つ目の出力が距離を、2 つ目の出力が対応するデータのインデックスを表します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEyff5OVUn1"
      },
      "source": [
        "model.kneighbors([x_train[0]], n_neighbors=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97hopA3DVUn3"
      },
      "source": [
        "今回は学習に使用した 0 番目のデータを使用して確認したため、もっとも近いもののインデックスは 0 、その距離も 0 となっています。  \n",
        "この距離に対して、閾値を設けることにより、異常検知に活用することができます。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKUcXHi_RW2z"
      },
      "source": [
        "### ロジスティック回帰\n",
        "\n",
        "ロジスティック回帰 (Logistic regression) は厳密には確率などを予測するための回帰のアルゴリズムに該当します。  \n",
        "しかし、確率を予測することが可能な特性から、分類の問題設定で用いられることが多いため、本章で紹介します。  \n",
        "\n",
        "予測値 $y$ を求める数式は下記のようになります。  \n",
        "\n",
        "$$\n",
        "{z = {\\beta}+w_1x_1+w_2x_2…\n",
        "}\n",
        "$$\n",
        "\n",
        "$$\n",
        "{y = \\frac{1}{1 + exp(-z)}\n",
        "}\n",
        "$$\n",
        "\n",
        "\n",
        "$z$ を求める式が重回帰分析で使用した数式と似ていることがわかると思います。  \n",
        "${\\beta}$ が切片を表し、$w_i$ が重みを表します。  \n",
        "\n",
        "$\\frac{1}{1 + exp(-z)}$ は[シグモイド関数](https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0)といいます。  \n",
        "図で表すと下記のようになります。  \n",
        "\n",
        "![シグモイド関数](http://drive.google.com/uc?export=view&id=1NFBsG5YBhNSE9Xkzposp_6gaCG4DQRwr)\n",
        "\n",
        "出典 : [Wikipedia](https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0#/media/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:SigmoidFunction.png)\n",
        "\n",
        "図からもわかるように、このシグモイド関数の適用後の $y$ は0~1の間に値をとります。  \n",
        "そのため、ロジスティック回帰は確率を取得することができると言えます。この確率をどのように分類に適用するかというと、それぞれのクラスに対し確率を予測し、その中で最も確率の高いクラスを予測値として採用します。  \n",
        "\n",
        "概要は下記になります。  \n",
        "\n",
        "| 項目                       | 説明                                                         |\n",
        "| -------------------------- | :----------------------------------------------------------- |\n",
        "| **強み**                   | 説明能力が高い。入力変数の重要度、オッズ比がわかる。 |\n",
        "| **弱み**                   | 複雑な問題設定に対応できない場合がある。                     |\n",
        "| **主なハイパーパラメータ** |                                                              |\n",
        "| *C（コストパラメータ）*    | 誤った予測に対するペナルティ。大き過ぎると過学習を起こす。     |\n",
        "| *penalty*                  | 正則化を行う方法を決定する。l1、l2 のノルムから選択する。         |\n",
        "\n",
        "詳細については[こちら](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0)を参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwQVZDUjPIi_"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(C=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBJUei-WwJ87"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofx3cqgwJ8-"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train, t_train))\n",
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnmEhmGuyV39"
      },
      "source": [
        "#### 重みの確認\n",
        "\n",
        "重回帰分析で行なった方法と同様に重み係数を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFqFipcGw_sG"
      },
      "source": [
        "print(model.coef_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCPRix5amgVb"
      },
      "source": [
        "plt.barh(y=dataset.feature_names ,width=model.coef_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfnpqbW10DqQ"
      },
      "source": [
        "#### オッズ比の確認\n",
        "\n",
        "オッズ比は重みに対して、 `np.exp()` で算出することができます。  \n",
        "注意点としてロジスティック回帰ではそのアルゴリズムの特性上重みから入力変数の影響度を判断することは難しく、一般的にこちらのオッズ比を用いて、影響度を確認することを覚えておきましょう。  \n",
        "\n",
        "オッズ比は分類結果への影響度を確認する際に使用することができます。  \n",
        "オッズ比の詳細は[こちら](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%83%E3%82%BA%E6%AF%94)を確認してください。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScB7hkcL0DkS"
      },
      "source": [
        "print(np.exp(model.coef_[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ1TfwGxmgbg"
      },
      "source": [
        "plt.barh(y=dataset.feature_names ,width=np.exp(model.coef_[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK8TtjRc8Rfl"
      },
      "source": [
        "#### 予測値の確率の確認\n",
        "\n",
        "分類のアルゴリズムには確率を予測できるものとそうでないものに分けることができます。  \n",
        "ロジスティック回帰のような確率を予測できるアルゴリズムでは `predict()` メソッドを用いる事により、推論を行い分類結果を取得でき、`predict_proba()` メソッドを使用することにより、推論を実行し、確率を取得することができます。  \n",
        "\n",
        "また、scikit-learn を用いて推論を行う際の入力値は行列である必要があります。例えばテストデータの 1 サンプル目を使用して、推論を行う際には `[x_test[0]]` とスライスした値を更に `[]` で囲う、もしくは `reshape()` メソッドでベクトルから行列に変換する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRen4Gkc8ceP"
      },
      "source": [
        "# ラベルの取得\n",
        "model.predict([x_test[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urEpfHLJ8nbr"
      },
      "source": [
        "各ラベルに対する確率を確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2yQ-cBh8cro"
      },
      "source": [
        "# 各ラベルに対する確率の確認\n",
        "model.predict_proba([x_test[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBrrmbEZ8ctt"
      },
      "source": [
        "ラベル 0 に対する確率が最も高いことが確認できました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YxsTWAUVUoZ"
      },
      "source": [
        "### 練習問題 分類のアルゴリズム\n",
        "\n",
        "これまでで学んだ内容を復習しましょう。下記の内容を次のセルに記述し、実行結果を確認してください。（必要に応じてセルの追加を行ってください。）  \n",
        "下記の内容を実行し、ロジスティック回帰を用いて、分類を行ってください。  \n",
        "\n",
        "- コードセルを実行し、データセットを読み込み入力変数 `x` と目標値 `t` の取得\n",
        "- 訓練用データセットとテスト用データセットに分割（テストデータの割合 : 30% 、random_state : 0）\n",
        "- ロジスティック回帰の実装（モデルの定義、モデルの学習、モデルの検証、推論）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XucTZPVUoZ"
      },
      "source": [
        "# データセットの読み込み\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "dataset = load_breast_cancer()\n",
        "x = dataset.data\n",
        "t = dataset.target\n",
        "columns = dataset.feature_names\n",
        "df = pd.DataFrame(x, columns=columns)\n",
        "df['Target'] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzewopTTVUob"
      },
      "source": [
        "# 読み込みんだデータセットの確認\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bOyoK6rVUod"
      },
      "source": [
        "# 訓練用データセットとテスト用データセットに分割（テストデータの割合 : 30% 、random_state : 0）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGz0FJ99VUog"
      },
      "source": [
        "# モデルの定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJyOk8dwVUoi"
      },
      "source": [
        "# モデルの学習\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeBcygRXVUok"
      },
      "source": [
        "# モデルの検証（訓練用データセット）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsbJI0r4VUol"
      },
      "source": [
        "# モデルの検証（テスト用データセット）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6QUmhITVUoo"
      },
      "source": [
        "# 推論（テスト用データセット）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwCNmeJZWf7P"
      },
      "source": [
        "#### 模範解答"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5_R_HWlWjLF"
      },
      "source": [
        "# データセットの読み込み\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "dataset = load_breast_cancer()\n",
        "x = dataset.data\n",
        "t = dataset.target\n",
        "columns = dataset.feature_names\n",
        "df = pd.DataFrame(x, columns=columns)\n",
        "df['Target'] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIDJNHoWjLQ"
      },
      "source": [
        "# 読み込みんだデータセットの確認\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D2i3Oc7WjLc"
      },
      "source": [
        "# 訓練用データセットとテスト用データセットに分割（テストデータの割合 : 30% 、random_state : 0）\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFHmnhtCWjLm"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(C=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u8LCjqDWjLw"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5FYBYFaWjL8"
      },
      "source": [
        "# モデルの検証\n",
        "print('train : ', model.score(x_train, t_train))\n",
        "print('test : ', model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_UZqq7DWjMY"
      },
      "source": [
        "# 推論（テスト用データセット）\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjBgIgzRXV-Q"
      },
      "source": [
        "ロジスティック回帰は分類を行う際の確率も取得することが可能です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Pmt6TDXKeM"
      },
      "source": [
        "# 推論：確率\n",
        "y_proba = model.predict_proba(x_test)\n",
        "y_proba[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yiqiwBEsI3L"
      },
      "source": [
        "## 分類の問題設定の評価方法\n",
        "\n",
        "### モデルを評価する指標  \n",
        "\n",
        "モデルを評価する指標には様々なものがあります。  \n",
        "代表的なものには下記が挙げられます。  \n",
        "\n",
        "- Accuracy （正解率）\n",
        "- Precision （適合率）\n",
        "- Recall （再現率）\n",
        "- F1 score （ F 値）  \n",
        "\n",
        "\n",
        "ここまで基本的に Accuracy （正解率）を用いて、分類のモデルの評価を行なってきました。   \n",
        "しかし、実問題ではこの Accuracy のみを用いて、モデルの良し悪しを決めてしまうとある危険性がある場合があります。  \n",
        "\n",
        "例えば、ラベルの種類が 2 種類しかないような 2 値分類の問題設定でデータセットの中身の 99% がラベル 0 、そして残りの 1% がラベル 1 というような割合の場合に Accuracy を最大化するためにどうするでしょうか。\n",
        "全てをラベル 0 と答え、ラベル 1 に対しては全く分類しないという選択を取ることが考えられます。  \n",
        "\n",
        "なぜならそのような選択を取ることにより、Accuracy は必然的に 99% になると言えるためです。  \n",
        "このような結果が望ましい問題設定もあれば、望ましくない問題設定もあることが考えられます。  \n",
        "\n",
        "がん患者の診断の例を用いて Accuracy 以外のモデルの評価指標について確認しましょう。   \n",
        "\n",
        "|          | 人数 |\n",
        "| -------- | ---- |\n",
        "| **全体** | 260  |\n",
        "| **健康な人** | 200   |\n",
        "| **がん患者** | 60    |\n",
        "\n",
        "上記のデータは目標値（実際の値）にあたります。  \n",
        "Precision などの Accuracy 以外の指標を理解するためにはこの目標値（実際の状態）と予測値（診察結果）の関係性を理解することが重要です。  \n",
        "\n",
        "診察結果（予測結果）を下記のような結果だとします。  \n",
        "下記の表は診察結果（列方向）と実際の状態（行方向）の関係を表した表になります。\n",
        "\n",
        "|  実際の状態(t)/診察結果(y) | 診断 : がん | 診断 : 健康 |\n",
        "| --------------------------- | ---------- | -------------- |\n",
        "| **実際 : がん**              | 10(TP)         | 50(FN)             |\n",
        "| **実際 : 健康**              | 5(FP)         | 195(TN)              |\n",
        "\n",
        "Precision などの指標について考えるにはこのような表、**混同行列 (Confusion matrix)** にして考えるのが一般的です。  \n",
        "それぞれの値には名前がついており、今回の例では下記のような意味を持ちます。  \n",
        "\n",
        "- TP → True Positive : 実際にがんであり、診断結果もがん\n",
        "- FP → False Positive : 実際は健康であり、診断結果はがん\n",
        "- FN → False Negative : 実際はがんであり、診断結果は健康\n",
        "- TN → True Negative : 実際は健康であり、診断結果も健康\n",
        "\n",
        "この混同行列を軸に分類の指標を確認していきます。  \n",
        "\n",
        "\n",
        "### Accuracy（正解率）\n",
        "\n",
        "この診察結果の場合、Accuracy は下記になります。\n",
        "\n",
        "*Accuracy（正解率）を求める式*  \n",
        "\n",
        "$\\frac{TP+TN}{TP+FP+TN+FN} = Accuracy$\n",
        "\n",
        "$\\frac{10+195}{10+5+50+195}=約79\\%$\n",
        "\n",
        "\n",
        "このように全ての値を足し合わせて、実際にどれだけあっているのかを測るのが、Accuracy です。  \n",
        "Accuracy は分類の精度を確認する為の指標として最も一般的なものです。  \n",
        "\n",
        "\n",
        "### Precision（適合率）\n",
        "\n",
        "次に紹介する Precision , Recall の評価指標は基準を置くラベルを決定する必要があります。  \n",
        "なぜなら Positive と Negative は決まったものではなく、Positive も Negative になりえ、Negative も Positive になりうる関係だからです。今回の例は上記の混同行列に合わせ、診断結果ががんだったものを Positive として扱い、Positive に着目し、それぞれの値を算出する例を紹介します。\n",
        "\n",
        "*Precision（適合率）を求める式*  \n",
        "\n",
        "$\\frac{TP}{TP+FP} = Precision$  \n",
        "\n",
        "$\\frac{実際がん患者}{がんと診断された人の総数}$  \n",
        "\n",
        "$\\frac{10}{10+5} = 約67\\%$  \n",
        "\n",
        "  \n",
        "使う場面は、 **間違いを少なく予測したい場合、だが取りこぼしは許される場面**になります。  \n",
        "下記の例を参考にもう少し具体的にイメージしてみましょう。\n",
        "\n",
        "> *例：裁判官が被疑者は無罪であることを前提に、冤罪を避けるために、有罪判決を下した場合は、\n",
        "> 有罪判決を受けた全ての被疑者は実際に有罪であるべきケース\n",
        "> （実際に有罪でありながら、無罪判決を行うのは問題ない）*\n",
        "\n",
        "このように基準となるクラスに対する予測値が間違っていることを避けたい場合に使用するのが Precision にあたります。  \n",
        "\n",
        "\n",
        "### Recall（再現率）\n",
        "\n",
        "*Recall（再現率）を求める式*   \n",
        "\n",
        "$\\frac{TP}{TP+FN} = Recall$    \n",
        "\n",
        "$\\frac{がんと診断された人で実際がん患者}{実際がん患者の総数}$    \n",
        "\n",
        "$\\frac{10}{10+50} = 約16\\%$  \n",
        "\n",
        "\n",
        "Recall は Precision とはトレードオフの関係にあります。  \n",
        "使う場面は、**取りこぼしを許したくない場合、だが間違いは許される場面**になります。  \n",
        "\n",
        "> *例：がん患者は全員見つけたい、健康な人はがんと診断しても問題ない（再診すればいい）  \n",
        "> （健康な人はがん患者と診断されても、再診すれば問題ないという前提のもと）*  \n",
        "\n",
        "今回のケースではこの Recall を評価指標として取り扱うことがいいと考えられでしょう。  \n",
        "もちろんどの指標を使用するかはそれぞれの問題設定に合わせて、選定する必要がある点を抑えておきましょう。  \n",
        "\n",
        "\n",
        "### F1 score（ F 値）\n",
        "\n",
        "Precision と Recall は少し極端な指標になります。なぜならどちらか一方のラベルに対しての Recall の値を 100% にするためには全てをそのラベルと予測することにより実現してしまうためです。  \n",
        "そこで考案されたのが、F1 score になります。両方の指標をバランスよく考慮したい場合などに用いられます。  \n",
        "計算方法は下記になります。\n",
        "\n",
        "*F値を求める式*   \n",
        "\n",
        "$\\frac{2 \\cdot Recall \\cdot Precision}{Recall + Precision}=F{\\unicode{x2013}} measure$\n",
        "\n",
        "上記で紹介した指標は簡単に scikit-learn の中で確認することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHGu_HqIhaMw"
      },
      "source": [
        "## scikit-learn で評価指標を確認\n",
        "\n",
        "### データの準備\n",
        "\n",
        "分類モデルにおける評価指標を議論する際には**不均衡データ**と呼ばれるデータ量に偏りがあるデータを使用すると分かり易いです。  \n",
        "データセットはこちらから [classification_imb.csv](http://drive.google.com/uc?export=view&id=1sEmAcyqePHcfphZWX-G8T9LLXMveWh0Z) をダウンロードして、Colab 上にアップロードして下さい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAMsLqw4se98"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6SzUdlsw--"
      },
      "source": [
        "# 必要なモジュールの読み込み\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaxeXPZGs3Lv"
      },
      "source": [
        "df = pd.read_csv('classification_imb.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV6279ops7MX"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15va6Kccm_4l"
      },
      "source": [
        "seaborn を用いて可視化します。`sns.countplot()` でデータの個数を集計し、可視化することができます。    \n",
        "目標値は今回 Target という列になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQM8M1UBtFsP"
      },
      "source": [
        "sns.countplot(df['Target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVFwszM8tI0-"
      },
      "source": [
        "今回は 0 と 1 のラベルがついた 2 値分類になります。  \n",
        "0 のラベルの数が少なく、不均衡なデータ （Imbalanced Data） の問題設定になります。\n",
        "\n",
        "入力変数 x と目標値 t の切り分けを行い、学習用データセットとテスト用データセットへの分割を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7lzrqD4tWiO"
      },
      "source": [
        "# 入力変数 x と目標値 t の切り分け\n",
        "x = df.iloc[:, :-1].values\n",
        "t = df['Target'].values\n",
        "print(x.shape, t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZT_FaQdtZ3g"
      },
      "source": [
        "# 学習用データセットとテスト用データセットの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-jfNFTDVUpB"
      },
      "source": [
        "### モデル構築\n",
        "\n",
        "ロジスティック回帰を使用してモデル構築を行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNaAcsCKtdHt"
      },
      "source": [
        "# モデルの定義\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN_fJlPZtg8k"
      },
      "source": [
        "# モデルの学習\n",
        "model.fit(x_train, t_train)\n",
        "\n",
        "# モデルの検証\n",
        "print(model.score(x_train, t_train))\n",
        "print(model.score(x_test, t_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEaMsd1qtlkF"
      },
      "source": [
        "上記のモデルの検証の部分で表示されている数値は Accuracy を表しています。  \n",
        "検証データに対しても、約 96% という予測精度のモデルができたように思えます。 \n",
        "\n",
        "実際に推論してみて、推論結果も確認してみます。  \n",
        "今回はテスト用データセット全てに対して予測を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwK6ZIx1twPo"
      },
      "source": [
        "# 推論\n",
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQYk0o0CVUpJ"
      },
      "source": [
        "予測値の中身を確認します。  \n",
        "NumPy の `.unique()` を使用することでベクトル内の重複を取り除いた、固有の値を確認することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KFO1T00tzsX"
      },
      "source": [
        "np.unique(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIPhvWt-t1ed"
      },
      "source": [
        "予測値全てがラベル 1 となっています。  \n",
        "目標値を確認して、この推論結果が正しいものか確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF8EudKWVUpK"
      },
      "source": [
        "np.unique(t_test, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_saj6uvVUpL"
      },
      "source": [
        "`return_counts` の引数を `True` と設定することにより、重複を取り除いた固有の値の数を集計することができます。  \n",
        "実際にはラベル 0 も 343 サンプルあることが確認できます。  \n",
        "\n",
        "このように Accuracy のみを指標として取り扱うと今回の不均衡なデータセットを取り扱う際などにはうまくその予測精度を評価することができない場合があることも覚えておきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SORGtx5-VUpM"
      },
      "source": [
        "### 混同行列\n",
        "\n",
        "その他の評価指標でも確認します。   \n",
        "まず、目標値と予測値を混同行列の形に落とし込みます。  \n",
        "\n",
        "scikit-learn で評価指標を確認する際には、`sklearn.metrics` モジュール内の関数を使用します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROpClUvKyBuN"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQteo9dHVUpN"
      },
      "source": [
        "# ラベルの取り出し\n",
        "labels = list(np.unique(t_train))\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0MWHNguAeH"
      },
      "source": [
        "# 混同行列の取得\n",
        "c_matrix = metrics.confusion_matrix(t_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7cUB7DBVUpQ"
      },
      "source": [
        "scikit-learn で取得した混同行列は NumPy の形式で格納されているため、Pandas のデータフレーム型にして、見やすく整形して表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9f0zoUzVUpQ"
      },
      "source": [
        "# データフレームに整形\n",
        "df_matrix = pd.DataFrame(c_matrix, columns=['がんと診断', '健康と診断'], index=['実際はがん', '実際は健康'])\n",
        "df_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDbwVaq4xrro"
      },
      "source": [
        "### Precision\n",
        "\n",
        "Precisionなどのスコアは `metrics` モジュール内の関数に、目標値と予測値を渡すことで確認することができます。  \n",
        "引数に `average=None` と指定することによって、それぞれのラベルを基準にしたスコアを確認することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VezIwsysy89i"
      },
      "source": [
        "precision = metrics.precision_score(t_test, y_pred, average=None)\n",
        "precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0XqZQRHzJU5"
      },
      "source": [
        "ラベル 0 に関しては予測数が 0 であるため、値が 0 となっています。  \n",
        "ラベル 1 に関しては予測した内の約 4 % 程度が間違っていることがわかります。\n",
        "\n",
        "### Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MxANAXzzI4o"
      },
      "source": [
        "recall = metrics.recall_score(t_test, y_pred, average=None)\n",
        "recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7wTpnnHzXTO"
      },
      "source": [
        "ラベル 0 に関しては予測数が 0 であるため、値が 0 となっています。  \n",
        "ラベル 1 に関しては目標値が 1 のラベルを全て予測できているため値が 100 % となっています。  \n",
        "\n",
        "### F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlQzG2w_zZgu"
      },
      "source": [
        "f1 = metrics.f1_score(t_test, y_pred, average=None)\n",
        "f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxJBOq1Xzake"
      },
      "source": [
        "F1 score ではちょうど Precision と Recall の間のような値を取得できていることが確認できます。  \n",
        "\n",
        "上記の評価指標の値を一括でまとめて確認する際には `metrics.precision_recall_fscore_support` を使用します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0GyY70Czg2-"
      },
      "source": [
        "# Precision, Recall, F値, 実際のそれぞれの値の合計をそれぞれ取得\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "pre, rec, fs, total =  precision_recall_fscore_support(t_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjMWmkI7zpBK"
      },
      "source": [
        "# データフレームに整形\n",
        "pd.DataFrame(np.array([total, pre, rec, fs]), index=['Total', 'Precision', 'Recall', 'F1 score'], columns=['ラベル 0','ラベル 1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dwZbFKYzrc-"
      },
      "source": [
        "このように分類の問題設定に取り組む際は、データの偏りなどに応じて評価指標を正しく選択し、評価を行うことが重要です。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPWtv4cTVUpf"
      },
      "source": [
        "## 練習問題 本章のまとめ\n",
        "\n",
        "本章で学んだ内容を復習しましょう。下記の内容を次のセルに記述し、実行結果を確認してください。（必要に応じてセルの追加を行ってください。）  \n",
        "\n",
        "\n",
        "- コードセルを実行し、データセットを読み込み入力変数 `x` と目標値 `t` の取得\n",
        "- 学習用データセットとテスト用データセットに分割（テストデータの割合 : 30% 、random_state : 0）\n",
        "- ロジスティック回帰の実装（モデルの定義、モデルの学習、モデルの検証）\n",
        "- テスト用データセットに対して推論を実行し、予測値を変数 `y_test` に格納\n",
        "- `t_test` と `y_test` を用いて混同行列の表示\n",
        "- 異なる分類指標で予測精度の確認（ Precision、Recall、F1 score ）\n",
        "\n",
        "*ヒント*  \n",
        "Precision などの値を確認する際に、引数の `average` を `None` に設定して、平均ではなくそれぞれの列を基準にした Precision、Recall、F1 score を確認しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYE3SEMRVUpf"
      },
      "source": [
        "# データセットの読み込み\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "dataset = load_breast_cancer()\n",
        "x = dataset.data\n",
        "t = dataset.target\n",
        "columns = dataset.feature_names\n",
        "df = pd.DataFrame(x, columns=columns)\n",
        "df['Target'] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2zf_GfJVUph"
      },
      "source": [
        "# 訓練用データセットとテスト用データセットに分割（テストデータの割合 : 30% 、random_state : 0）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSFq6gFvVUpi"
      },
      "source": [
        "# モデルの定義\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E7maSTTVUpj"
      },
      "source": [
        "# モデルの学習\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yiv-U-YVUpl"
      },
      "source": [
        "# モデルの検証\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_V9izFVUpn"
      },
      "source": [
        "# 推論結果を y_test に格納\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duqDotPuVUps"
      },
      "source": [
        "# 混同行列の表示\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4Glnp0DVUpt"
      },
      "source": [
        "# Precision の取得（ average を None に設定）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KCAIq1pVUpv"
      },
      "source": [
        "# Recall の取得（ average を None に設定）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgakmwsnVUpx"
      },
      "source": [
        "# F1 score の取得（ average を None に設定）\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr-6w8vBVUpz"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1g2xjXbw5qYeqdJqcOf3uASvzBQxhlE8u\" width=30%>"
      ]
    }
  ]
}